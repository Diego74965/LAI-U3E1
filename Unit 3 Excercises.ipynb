{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd1d67ec",
   "metadata": {},
   "source": [
    "# Unit 3, Exercise 1: Banknote Authentication\n",
    "In this exercise, we are applying logistic regression to a banknote authentication dataset to distinguish between genuine and forged bank notes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed819c8",
   "metadata": {},
   "source": [
    "**The dataset consists of 1372 examples and 4 features for binary classification.** The features are:\n",
    "1. Variance of wavelet-transformed image\n",
    "2. Skewness of wavelet-transformed image\n",
    "3. Kurtosis of a wavelet-transformed image\n",
    "4. Entropy of the image\n",
    "\n",
    "<sub>\n",
    "    Details about this dataset <a href=\"https://archive.ics.uci.edu/ml/datasets/banknote+authentication\">https://archive.ics.uci.edu/ml/datasets/banknote+authentication</a>\n",
    "    </sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60499a05",
   "metadata": {},
   "source": [
    "In essence, these four features represent features that were manually extracted from image data.\n",
    "\n",
    "You are ecouraged to explore the dataset further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eb96e9",
   "metadata": {},
   "source": [
    "## 1) Installing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c510fb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.9.15\n",
      "IPython version      : 7.31.1\n",
      "\n",
      "numpy     : 1.23.5\n",
      "pandas    : 1.4.4\n",
      "matplotlib: 3.6.2\n",
      "torch     : 1.13.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -p numpy,pandas,matplotlib,torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095899ce",
   "metadata": {},
   "source": [
    "## 2) Loading the Dataset\n",
    "We are using the familiar `read_csv` function from pandas to load the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0deb0ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3a5c5ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2        3  4\n",
       "0  3.62160  8.6661 -2.8073 -0.44699  0\n",
       "1  4.54590  8.1674 -2.4586 -1.46210  0\n",
       "2  3.86600 -2.6383  1.9242  0.10645  0\n",
       "3  3.45660  9.5228 -4.0112 -3.59440  0\n",
       "4  0.32924 -4.4552  4.5718 -0.98880  0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data_banknote_authentication.txt\", header = None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45c923ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_features = df[[0, 1, 2, 3]].values\n",
    "y_labels = df[4].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d7f5db",
   "metadata": {},
   "source": [
    "Number of examples and features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba261c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1372, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_features.shape\n",
    "# 1372 examples, 4 features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5035b6",
   "metadata": {},
   "source": [
    "Looking at the label distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a41ddf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "791d8920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([762, 610], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7ef3e5",
   "metadata": {},
   "source": [
    "## 3) Descriptive analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6ec8532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.433735\n",
       "1    1.922353\n",
       "2    1.397627\n",
       "3   -1.191657\n",
       "4    0.444606\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42f13cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    -7.0421\n",
       "1   -13.7731\n",
       "2    -5.2861\n",
       "3    -8.5482\n",
       "4     0.0000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a89e3f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     6.8248\n",
       "1    12.9516\n",
       "2    17.9274\n",
       "3     2.4495\n",
       "4     1.0000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8d60da",
   "metadata": {},
   "source": [
    "## 4) Defining a DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2deb4ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3103ad40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.features = torch.tensor(x, dtype = torch.float32)\n",
    "        self.labels = torch.tensor(y, dtype = torch.float32)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.features[index]\n",
    "        y = self.labels[index]\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d7a0cf",
   "metadata": {},
   "source": [
    "We will be using 80% of the data for training, 20% of the data for validation. In real life, we would also have a separate dataset for the final test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "097d2aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1097"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(x_features.shape[0]*0.80)\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3ed6a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_size = x_features.shape[0] - train_size\n",
    "val_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caba1cff",
   "metadata": {},
   "source": [
    "Using `torch.utils.data.random_split`, we generate the training and validation sets along with the respective data loaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3159608b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bfcb8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(x_features, y_labels)\n",
    "\n",
    "torch.manual_seed(74)\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset = train_set,\n",
    "    batch_size = 10,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset = val_set,\n",
    "    batch_size = 10,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d49c09",
   "metadata": {},
   "source": [
    "## 5) Implementing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12bd1c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression model\n",
    "\n",
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(num_features, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = self.linear(x)\n",
    "        probas = torch.sigmoid(logits)\n",
    "        return probas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6257a809",
   "metadata": {},
   "source": [
    "## 6) The training loop\n",
    "In this section, we are using the training loopfrom Unit 3.6. We added the line `if not batch_idx % 20` to only print the loss for every 20th batch (to simplify output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd52e00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 000/110 | Loss: 1.86\n",
      "Epoch: 001/010 | Batch 040/110 | Loss: 0.18\n",
      "Epoch: 001/010 | Batch 080/110 | Loss: 0.17\n",
      "Epoch: 002/010 | Batch 000/110 | Loss: 0.17\n",
      "Epoch: 002/010 | Batch 040/110 | Loss: 0.05\n",
      "Epoch: 002/010 | Batch 080/110 | Loss: 0.12\n",
      "Epoch: 003/010 | Batch 000/110 | Loss: 0.09\n",
      "Epoch: 003/010 | Batch 040/110 | Loss: 0.03\n",
      "Epoch: 003/010 | Batch 080/110 | Loss: 0.03\n",
      "Epoch: 004/010 | Batch 000/110 | Loss: 0.06\n",
      "Epoch: 004/010 | Batch 040/110 | Loss: 0.19\n",
      "Epoch: 004/010 | Batch 080/110 | Loss: 0.05\n",
      "Epoch: 005/010 | Batch 000/110 | Loss: 0.10\n",
      "Epoch: 005/010 | Batch 040/110 | Loss: 0.04\n",
      "Epoch: 005/010 | Batch 080/110 | Loss: 0.04\n",
      "Epoch: 006/010 | Batch 000/110 | Loss: 0.16\n",
      "Epoch: 006/010 | Batch 040/110 | Loss: 0.16\n",
      "Epoch: 006/010 | Batch 080/110 | Loss: 0.06\n",
      "Epoch: 007/010 | Batch 000/110 | Loss: 0.12\n",
      "Epoch: 007/010 | Batch 040/110 | Loss: 0.16\n",
      "Epoch: 007/010 | Batch 080/110 | Loss: 0.16\n",
      "Epoch: 008/010 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 008/010 | Batch 040/110 | Loss: 0.08\n",
      "Epoch: 008/010 | Batch 080/110 | Loss: 0.13\n",
      "Epoch: 009/010 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 009/010 | Batch 040/110 | Loss: 0.15\n",
      "Epoch: 009/010 | Batch 080/110 | Loss: 0.07\n",
      "Epoch: 010/010 | Batch 000/110 | Loss: 0.04\n",
      "Epoch: 010/010 | Batch 040/110 | Loss: 0.07\n",
      "Epoch: 010/010 | Batch 080/110 | Loss: 0.01\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(1)\n",
    "model = LogisticRegression(num_features = 4)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.04)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    model = model.train()\n",
    "    for batch_idx, (features, class_labels) in enumerate(train_loader):\n",
    "        probas = model(features)\n",
    "        \n",
    "        loss = F.binary_cross_entropy(probas, class_labels.view(probas.shape))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #Logging\n",
    "        if not batch_idx % 40:\n",
    "            print(f'Epoch: {epoch+1:03d}/{num_epochs:03d}'\n",
    "                  f' | Batch {batch_idx:03d}/{len(train_loader):03d}'\n",
    "                  f' | Loss: {loss:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b6cc4d",
   "metadata": {},
   "source": [
    "## 7) Evaluating the results\n",
    "Reusing the code from Unit 3.6, we will calculate the training and validation set accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8929d0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, dataloader):\n",
    "    model = model.eval()\n",
    "    \n",
    "    correct = 0.0\n",
    "    total_examples = 0\n",
    "    \n",
    "    for idx, (features, class_labels) in enumerate(dataloader):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            probas = model(features)\n",
    "            \n",
    "        pred = torch.where(probas > 0.5, 1, 0)\n",
    "        lab = class_labels.view(pred.shape).to(pred.dtype)\n",
    "        \n",
    "        compare = lab == pred\n",
    "        correct += torch.sum(compare)\n",
    "        total_examples += len(compare)\n",
    "        \n",
    "    return correct / total_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95b1ab81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  98.81%\n"
     ]
    }
   ],
   "source": [
    "train_acc = compute_accuracy(model, train_loader)\n",
    "print(f\"Accuracy: {train_acc * 100: .2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d172a24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  98.18%\n"
     ]
    }
   ],
   "source": [
    "val_acc = compute_accuracy(model, val_loader)\n",
    "print(f\"Accuracy: {val_acc * 100: .2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2764378a",
   "metadata": {},
   "source": [
    "We find that the best learning rate and number of epochs is 0.05 and 10 respectievly. These values gives us a training accuracy of >99% and a validation accuracy of >98%.\n",
    "\n",
    "**Training Accuracy:** The accuracy of the model on the data it was trained on.\n",
    "\n",
    "**Validation Accuracy:** The accuracy of the model on a separate set of data that was not used during training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
